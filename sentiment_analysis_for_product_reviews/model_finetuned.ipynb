{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a notebook to test the DistilBERT model\n",
    "import tensorflow as tf\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from transformers import TFDistilBertForSequenceClassification\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Reviews.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score                                               Text\n",
       "0      5  I have bought several of the Vitality canned d...\n",
       "1      1  Product arrived labeled as Jumbo Salted Peanut...\n",
       "2      4  This is a confection that has been around a fe...\n",
       "3      2  If you are looking for the secret ingredient i...\n",
       "4      5  Great taffy at a great price.  There was a wid..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy=df.copy()\n",
    "df_copy.drop(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Time', 'Summary'],\n",
    "             inplace=True, axis=1)\n",
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy[\"Sentiment\"] = df_copy[\"Score\"].apply(lambda score: \"positive\" if score >= 3 else (\"negative\" if score <= 2 else \"neutral\"))\n",
    "df_copy['Sentiment'] = df_copy['Sentiment'].map({'positive':1, 'negative':0, 'neutral':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score                                               Text  Sentiment\n",
       "0      5  I have bought several of the Vitality canned d...          1\n",
       "1      1  Product arrived labeled as Jumbo Salted Peanut...          0\n",
       "2      4  This is a confection that has been around a fe...          1\n",
       "3      2  If you are looking for the secret ingredient i...          0\n",
       "4      5  Great taffy at a great price.  There was a wid...          1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568454, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=df_copy[[\"Sentiment\",\"Text\"]]\n",
    "data.head()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = data['Text'].values.tolist()\n",
    "labels = data['Sentiment'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "training_sentences, validation_sentences, training_labels, validation_labels = train_test_split(reviews, labels, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1996, 5510, 1997, 2122, 2317, 18178, 25062, 2099, 4257, 7852, 2015, 2003, 2066, 1037, 3180, 8579, 2121, 1011, 2029, 2003, 2025, 2919, 1010, 3272, 2008, 1045, 4149, 2068, 2138, 1045, 2359, 1037, 8808, 5510, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2054, 2001, 1037, 4121, 10520, 1029, 2129, 22369, 1996, 14793, 1997, 1996, 3482, 2003, 1012, 1996, 6302, 2006, 1996, 3482, 1006, 1045, 4149, 2122, 1999, 3573, 1007, 3084, 2009, 2298, 2066, 2009, 2003, 2440, 1997, 2146, 4257, 27035, 2015, 1006, 9186, 1996, 3091, 1998, 9381, 1997, 1996, 3482, 1007, 1012, 3308, 999, 1996, 6081, 11851, 2008, 4324, 1996, 8579, 2545, 2003, 2055, 1016, 1000, 3760, 2035, 2105, 1011, 2975, 2017, 2007, 2055, 2321, 2030, 2061, 2235, 4257, 27035, 2015, 1012, 1026, 7987, 1013, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "tokenizer([training_sentences[0]], truncation=True, padding=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(training_sentences,truncation=True,padding=True)\n",
    "val_encodings = tokenizer(validation_sentences,truncation=True,padding=True)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings),training_labels))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((dict(val_encodings),validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased',num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    training_labels\n",
    "))\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings),\n",
    "    validation_labels\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5, epsilon=1e-08)\n",
    "model.compile(optimizer=optimizer, loss=model.hf_compute_loss, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "50/50 [==============================] - 723s 14s/step - loss: 0.3866 - accuracy: 0.8487 - val_loss: 0.3372 - val_accuracy: 0.8600\n",
      "Epoch 2/3\n",
      "50/50 [==============================] - 731s 15s/step - loss: 0.2296 - accuracy: 0.9175 - val_loss: 0.3175 - val_accuracy: 0.8650\n",
      "Epoch 3/3\n",
      "50/50 [==============================] - 710s 14s/step - loss: 0.0944 - accuracy: 0.9762 - val_loss: 0.3109 - val_accuracy: 0.9100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2c2e884c910>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset.shuffle(100).batch(16),\n",
    "          epochs=3,\n",
    "          validation_data=val_dataset.shuffle(100).batch(16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at C:\\Users\\Asus\\Desktop\\Submission\\sentiment\\tf_model.h5 were not used when initializing TFDistilBertForSequenceClassification: ['dropout_39']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at C:\\Users\\Asus\\Desktop\\Submission\\sentiment\\tf_model.h5 and are newly initialized: ['dropout_199']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFDistilBertForSequenceClassification\n",
    "\n",
    "# Load the Hugging Face Transformers model\n",
    "transformers_model = TFDistilBertForSequenceClassification.from_pretrained(\n",
    "    r\"C:\\Users\\Asus\\Desktop\\Submission\\sentiment\\tf_model.h5\",\n",
    "    config=r\"C:\\Users\\Asus\\Desktop\\Submission\\sentiment\\config.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check model prediction\n",
    "\n",
    "def senti(test_sentence):\n",
    "    try:\n",
    "        predict_input = tokenizer.encode(test_sentence,\n",
    "                                          truncation=True,\n",
    "                                          padding=True,\n",
    "                                          return_tensors=\"tf\")\n",
    "        tf_output = transformers_model.predict(predict_input)[0]\n",
    "        tf_prediction = tf.nn.softmax(tf_output, axis=1)\n",
    "        labels = ['Negative', 'Positive', 'Neutral']\n",
    "        label_index = tf.argmax(tf_prediction, axis=1).numpy()[0]\n",
    "        predicted_label = labels[label_index]\n",
    "        return predicted_label\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", str(e))\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence = \"I love this product\"\n",
    "test_sentence1 = \"This is worst food\"\n",
    "senti(test_sentence)\n",
    "senti(test_sentence1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have fine-tuned the model using the following hyperparameters:\n",
    "- batch_size = 16\n",
    "- learning_rate = 5e-5\n",
    "- epochs = 3\n",
    "- epsilon=1e-08\n",
    "- optimizer = Adam\n",
    "- metrics = accuracy\n",
    "- validation_split = 0.2\n",
    "- shuffle = True\n",
    "\n",
    "\n",
    "I have fine-tuned the model for 1000 data points only and the model is performing well on the test data. But the model can be further fine-tuned for better performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
